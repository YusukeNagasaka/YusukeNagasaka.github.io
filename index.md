---
layout: default
---

<!--I'm a Ph.D Student at Dept. of Mathematical and Computing Science, Tokyo Institute of Technology.-->

# Research Interests

> Acceleration of Sparse Matrix Computation on Many-core Processors
*   Sparse Matrix Vector Multiplication (SpMV)
*   Sparse General Matrix-Matrix Multiplication (SpGEMM)

> Random Number Generator
*   Multiple Recursive Generator with 8th-order Full Primitive Polynomials (MRG8) for Many-core Processors

# Publication

### Lists

*   [Google Scholar](https://scholar.google.co.jp/citations?user=7XBJiZsAAAAJ&hl=ja)
*   [Tokyo Tech Research Repository (T2R2)](http://t2r2.star.titech.ac.jp/cgi-bin/publicationlist.cgi?q_rcn=CTT100605619&viewstyle=ListStyle&author_name_style_id_ja=lnfn&author_name_style_id_en=Fn+Ln&viewlang=1&group_by=Year%3ADESC&order_by=Month%3ADESC,Title%3AASC%3Aja)


### Papers

*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, **"Cache-aware sparse matrix formats for Kepler GPU"**, 20th IEEE International Conference on Parallel and Distributed Systems (ICPADS),  Hsinchu, Taiwan, December 2014. [[DOI](http://ieeexplore.ieee.org/document/7097819/)] [[Slides](./material/slides/icpads14_nagasaka.pdf)]
*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, **"Adaptive Multi-level Blocking Optimization for Sparse Matrix Vector Multiplication on GPU"**, International Conference on Computational Science 2016 (ICCS 2016), San Diego, California, USA, June 2016. [[DOI](http://www.sciencedirect.com/science/article/pii/S187705091630655X)] [[Slides](./material/slides/1606_nagasaka_iccs.pdf)]
*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, **"High-performance and Memory-saving Sparse General Matrix-Matrix Multiplication for NVIDIA Pascal GPU"**, International Conference on Parallel Processing 2017 (ICPP 2017), Bristol, UK, August 2017. [[DOI](http://ieeexplore.ieee.org/abstract/document/8025284/)] [[Slides](./material/slides/20170815_nagasaka_icpp2017.pdf)]
*   Yusuke Nagasaka, Akira Nukada, Satoshi Matsuoka, Kenichi Miura, John Shalf, **"MRG8 - Random Number Generation for the Exascale Era"**, The Platform for Advanced Scientific Computing Conference (PASC18), Basel, Switzerland, 2018. [[DOI](https://dl.acm.org/citation.cfm?id=3218230)] [[Slides](./material/slides/20180703_pasc18_nagasaka.pdf)]
*   Yusuke Nagasaka, Satoshi Matsuoka, Ariful Azad and Aydın Buluç, **"High-performance sparse matrix-matrix products on Intel KNL and multicore architectures"**, International Workshop on Parallel Programming Models and Systems Software for High-End Computing (P2S2), held in conjunction with ICPP 2018, Eugene, Oregon, USA, 2018. [[DOI](https://doi.org/10.1145/3229710.3229720)] [[Slides](./material/slides/201808_p2s2_spgemm.pdf)]
*   Yusuke Nagasaka, Akira Nukada, Ryosuke Kojima, Satoshi Matsuoka, **"Batched Sparse Matrix Multiplication for Accelerating Graph Convolutional Networks"**, The 19th Annual IEEE/ACM International Symposium in Cluster, Cloud, and Grid Computing (CCGrid 2019), Larnaca, Cyprus, 2019 (to be appeared).
*   長坂侑亮, 額田彰, 松岡聡, **"GPUのキャッシュを考慮した疎行列ベクトル積計算手法の性能評価"**, 情報処理学会研究報告 HPC-144, 横浜, 2014年5月. [[DOI](http://id.nii.ac.jp/1001/00101379/)]
*   長坂侑亮, 額田彰, 松岡聡, **"疎行列ベクトル積計算を対象としたGPU向けメモリアクセス削減手法"**, 情報処理学会研究報告 HPC-151, 那覇, 2015年9月. [[DOI](http://id.nii.ac.jp/1001/00145058/)]
*   長坂侑亮, 額田彰, 松岡聡, **"メモリ使用量を抑えた疎行列疎行列積計算のGPU高速化"**, 情報処理学会研究報告 HPC-156, 小樽, 2016年9月. [[DOI](http://id.nii.ac.jp/1001/00174439/)]
*   長坂侑亮, 額田彰, 小島諒介, 松岡聡, **"GraphCNN向けの疎行列積計算Batch最適化"**, 情報処理学会研究報告 HPC-167, 那覇, 2018年12月. [[DOI](http://id.nii.ac.jp/1001/00192743/)]
*   長坂侑亮, 額田彰, 小島諒介, 松岡聡, **"小疎行列積計算のGPU最適化"**, 情報処理学会研究報告 HPC-168, 加賀, 2019年3月. [[DOI](http://id.nii.ac.jp/1001/00194701)]


### Posters
*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, **"Cache-aware Sparse Matrix Format for GPU"**, International Superconputing Conference (ISC'14) HPC in Asia Posters, Leipzig, Germany, June 2014.
*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, **"Multi-Level Blocking Optimization for Fast Sparse Matrix Vector Multiplication on GPUs"**, The International Conference for High Performance Computing, Networking, Storage and Analysis (SC15) Technical Program Posters, Austin, Texas, USA, November 2015. [[Link](http://sc15.supercomputing.org/sites/all/themes/SC15images/tech_poster/tech_poster_pages/post332.html)]
*   Yusuke Nagasaka, **"Fast Sparse Matrix Vector Multiplication with Highly-Compressed Sparse Format"**, GPU Technology Conference (GTC2016), San Jose, CA, USA, April 2016. [[Link](http://on-demand.gputechconf.com/gtc/2016/posters/GTC_2016_Algorithms_AL_09_P6132_WEB.pdf)]
*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, **"Fast Sparse General Matrix-Matrix Multiplication on GPU with Low Memory Usage"**, The International Conference for High Performance Computing, Networking, Storage and Analysis (SC16) Technical Program Posters, Salt Lake City, Utah, USA, November 2016. [[Link](http://sc16.supercomputing.org/sc-archive/tech_poster/tech_poster_pages/post180.html)]
*   Yusuke Nagasaka, **"Fast and Memory-saving SpGEMM Algorithm for New Pascal Generation GPU"**, GPU Technology Conference (GTC2017), San Jose, CA, USA, May 2017. [[Link](http://www.gputechconf.com/resources/poster-gallery/2017/algorithms)]
*   Yusuke Nagasaka, **"Boosting GCN Application with Batched Sparse Matrix Multiplication"**, GPU Technology Conference (GTC2019), San Jose, CA, USA, March 2019. <!--[<a href="">Link</a>]-->
*   長坂侑亮, **"GPUでのキャッシュ再利用性を考慮した列分割型疎行列フォーマットの性能評価"**, GPU テクノロジ・カンファレンス(GTC Japan 2014), 東京, 2014年7月.
*   長坂侑亮, **"多段階ブロッキングによるメモリアクセス量削減を図ったGPU向け疎行列ベクトル積計算手法の性能評価"**, GPU テクノロジ・カンファレンス(GTC Japan 2015), 東京, 2015年9月.
*   Yusuke Nagasaka, **"MRG8 - High Throughput Random Number Generation for GPU"**, GPU テクノロジ・カンファレンス(GTC Japan 2018), 東京, 2018年9月.


### Talks

*   Yusuke Nagasaka **"Exploiting GPU Caches in Sparse Matrix Vector Multiplication"**, GPU Technology Conference (GTC2015), San Jose, CA, USA, March 2015. [[Link](http://on-demand.gputechconf.com/gtc/2015/presentation/S5518-Yusuke-Nagasaka.pdf)]
*   Yusuke Nagasaka, Akira Nukada and Satoshi Matsuoka, Ariful Azad and Aydın Buluç, **"Efficient Sparse General Matrix-Matrix Multiplication Algorithms for Many-Core Processors"**, SIAM PP 2018, Tokyo, Japan, March 2018. [[Link](http://meetings.siam.org/sess/dsp_talk.cfm?p=89387)]


### Awards
*   2015年度情報処理学会コンピュータサイエンス領域奨励賞. [[Link](https://www.ipsj.or.jp/award/cs-awardee-2015.html)]


# Software

### nsparse 
Fast Sparse Matrix Library for GPU. Supporting SpMV with AMB format and Hash-table based SpGEMM.  
[GitHub Link](https://github.com/EBD-CREST/nsparse)


# Experiences
### Joint Research
#### 2015, 2016
学際大規模情報基盤共同利用・共同研究拠点 共同研究  
jh150046-NA24 "超大規模シミュレーションのためのアーキテクチャ特性を考慮した通信削減技術"

### Teaching Assistant
#### 2016, 2017
Working as teaching assistant of the courses on computer system and high-performance computing at Tokyo Institute of Technology.

### Internship
#### May - July, 2017
Summer internship at Lawrence Berkeley National Laboratory (LBNL).


# Education

### Bachelor of Science
Tokyo Institute of Technology, Dept. of Information Science  
April 2010 - March 2014  
> Bachelor Thesis: **"キャッシュを考慮したSPMVのGPU高速化"**  
> Supervisor: Prof. Satoshi Matsuoka

### Master of Science
Tokyo Institute of Technology, Dept. of Mathematical and Computing Sciences  
April 2014 - March 2016  
> Master Thesis: **"メモリアクセス量削減による疎行列ベクトル積計算のメニーコア向け高速化"**  
> Supervisor: Prof. Satoshi Matsuoka

### Doctor of Science
Tokyo Institute of Technology, Dept. of Mathematical and Computing Science  
April 2016 - March 2019
> Doctor Thesis: **"Performance Optimization of Sparse Matrix Kernels for Many-core Architectures (メニーコアアーキテクチャにおける疎行列計算の性能最適化)"**
> Supervisor: Prof. Satoshi Matsuoka

# Contact
> E-mail: nagasaka.mlab [at] gmail.com


